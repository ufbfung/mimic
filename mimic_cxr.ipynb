{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOFNSQpA5OoTQ4UOrCSwea5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ufbfung/mimic/blob/main/mimic_cxr.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MIMIC-III Dataset\n",
        "Access to the MIMIC-III dataset can be found at PhysioNet website (https://physionet.org/content/mimiciii/1.4/).\n",
        "\n",
        "Freely available for non-commercial research purposes, but requires approval.\n",
        "\n",
        "# MIMIC-IV Dataset\n",
        "Copied directly from [Physionet MIMIC-IV](https://physionet.org/content/mimiciv/2.2/)\n",
        "\n",
        "## Abstract\n",
        "Retrospectively collected medical data has the opportunity to improve patient care through knowledge discovery and algorithm development. Broad reuse of medical data is desirable for the greatest public good, but data sharing must be done in a manner which protects patient privacy. The Medical Information Mart for Intensive Care (MIMIC)-III database provided critical care data for over 40,000 patients admitted to intensive care units at the Beth Israel Deaconess Medical Center (BIDMC). Importantly, MIMIC-III was deidentified, and patient identifiers were removed according to the Health Insurance Portability and Accountability Act (HIPAA) Safe Harbor provision. MIMIC-III has been integral in driving large amounts of research in clinical informatics, epidemiology, and machine learning. Here we present MIMIC-IV, an update to MIMIC-III, which incorporates contemporary data and improves on numerous aspects of MIMIC-III. MIMIC-IV adopts a modular approach to data organization, highlighting data provenance and facilitating both individual and combined use of disparate data sources. MIMIC-IV is intended to carry on the success of MIMIC-III and support a broad set of applications within healthcare.\n",
        "\n",
        "## Background\n",
        "In recent years there has been a concerted move towards the adoption of digital health record systems in hospitals. In the US, nearly 96% of hospitals had a digital electronic health record system (EHR) in 2015 [1]. Retrospectively collected medical data has increasingly been used for epidemiology and predictive modeling. The latter is in part due to the effectiveness of modeling approaches on large datasets [2]. Despite these advances, access to medical data to improve patient care remains a significant challenge. While the reasons for limited sharing of medical data are multifaceted, concerns around patient privacy are highlighted as one of the most significant issues. Although patient studies have shown almost uniform agreement that deidentified medical data should be used to improve medical practice, domain experts continue to debate the optimal mechanisms of doing so. Uniquely, the MIMIC-III database adopted a permissive access scheme which allowed for broad reuse of the data [3]. This mechanism has been successful in the wide use of MIMIC-III in a variety of studies ranging from assessment of treatment efficacy in well defined cohorts to prediction of key patient outcomes such as mortality. MIMIC-IV aims to carry on the success of MIMIC-III, with a number of changes to improve usability of the data and enable more research applications.\n",
        "\n",
        "## Methods\n",
        "MIMIC-IV is sourced from two in-hospital database systems: a custom hospital wide EHR and an ICU specific clinical information system. The creation of MIMIC-IV was carried out in three steps:\n",
        "\n",
        "- Acquisition. Data for patients who were admitted to the BIDMC emergency department or one of the intensive care units were extracted from the respective hospital databases. A master patient list was created which contained all medical record numbers corresponding to patients admitted to an ICU or the emergency department between 2008 - 2019. All source tables were filtered to only rows related to patients in the master patient list.\n",
        "- Preparation. The data were reorganized to better facilitate retrospective data analysis. This included the denormalization of tables, removal of audit trails, and reorganization into fewer tables. The aim of this process is to simplify retrospective analysis of the database. Importantly, data cleaning steps were not performed, to ensure the data reflects a real-world clinical dataset.\n",
        "- Deidentify. Patient identifiers as stipulated by HIPAA were removed. Patient identifiers were replaced using a random cipher, resulting in deidentified integer identifiers for patients, hospitalizations, and ICU stays. Structured data were filtered using look up tables and allow lists. If necessary, a free-text deidentification algorithm was applied to remove PHI from free-text. Finally, date and times were shifted randomly into the future using an offset measured in days. A single date shift was assigned to each subject_id. As a result, the data for a single patient are internally consistent. For example, if the time between two measures in the database was 4 hours in the raw data, then the calculated time difference in MIMIC-IV will also be 4 hours. Conversely, distinct patients are not temporally comparable. That is, two patients admitted in 2130 were not necessarily admitted in the same year.\n",
        "\n",
        "After these three steps were carried out, the database was exported to a character based comma delimited format.\n",
        "\n",
        "## Release Notes\n",
        "### MIMIC-IV v2.2\n",
        "MIMIC-IV v2.2 was released in January 2023. It added provider identifiers, imputed hadm_id for a number of rows in emar, and changed the subset of subject_id which are held out. Final row counts are available in the validation scripts published with the MIMIC Code Repository [6]. For clarity, after removal of the test set, the row counts are as follows:\n",
        "\n",
        "- patients: 299,712 (was 315,460 in v2.0)\n",
        "- admissions: 431,231 (was 454,324 in v2.0)\n",
        "- icustays: 73,181 (was 76,943 in v2.0)\n"
      ],
      "metadata": {
        "id": "jVRYprhTRT0Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MIMIC-CXR\n",
        "This notebook will explore the new chest x-ray repository from mimic."
      ],
      "metadata": {
        "id": "-GyAK6-2cLzA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup environment\n"
      ],
      "metadata": {
        "id": "HDTXEIyuRWBt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load environment variables\n",
        "This section is just a template for future querying. Not used currently."
      ],
      "metadata": {
        "id": "fRu7vpcpRchv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "# Load variables from .env file\n",
        "load_dotenv('credentials.env')\n",
        "\n",
        "# Access the variables\n",
        "username = os.getenv('mimic_username')\n",
        "password = os.getenv('mimic_password')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jj0K7WNyRiRf",
        "outputId": "3b496e16-8a9d-40af-fb54-3f65ca620d5d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Integrate with BigQuery\n",
        "This section will allow integration with Google BigQuery to bring data into your Colab instance."
      ],
      "metadata": {
        "id": "0ll_P10pSieZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Authenticate and authorize Colab Notebook\n",
        "This step will install relevant libraries for authentication and authorization and also authenticate your Colab notebook to connect to Google BigQuery."
      ],
      "metadata": {
        "id": "NtLwOkhjRswa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install relevant libraries\n",
        "from google.colab import auth # this provides functions for authenticating and authorizing your Google account within the Colab environment\n",
        "\n",
        "# Authenticate\n",
        "auth.authenticate_user() # this initiates the authentication process which will prompt you to authenticate your Google account. The purpose of this authentication is to allow your Colab notebook to access Google Cloud services, such as BigQuery, using your authorized account."
      ],
      "metadata": {
        "id": "huYUmwPZRwlX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a client\n",
        "This step will create a client to access a specific project within BigQuery. You will want to copy the name of the project you're interested in querying from BigQuery and set it to the project variable."
      ],
      "metadata": {
        "id": "y43pP3aER1sc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install relevant library\n",
        "from google.cloud import bigquery\n",
        "\n",
        "# Define project you're interested in querying from BigQuery\n",
        "project = 'mimic-iv-390722'\n",
        "\n",
        "# Create a client\n",
        "client = bigquery.Client(project=project)"
      ],
      "metadata": {
        "id": "2Peri3gWR4y3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Write a query\n",
        "This step involves writing an SQL query you want to use. Below is a simple query that can be used to quickly check the connection"
      ],
      "metadata": {
        "id": "z7BD6SJuSDOc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a sample query to check connection\n",
        "query = \"\"\"\n",
        "SELECT *\n",
        "FROM `physionet-data.mimiciii_clinical.admissions`\n",
        "LIMIT 5\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "vEW7e-ohSFpb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run the query & get results\n"
      ],
      "metadata": {
        "id": "Bj3R0wkBSP_J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the query\n",
        "query_job = client.query(query)\n",
        "\n",
        "# Get the results\n",
        "results = query_job.result()"
      ],
      "metadata": {
        "id": "IizesHn9SSI8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Process and extract the data\n",
        "This will process the data from the query and print them"
      ],
      "metadata": {
        "id": "TZeYkietSTaj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Process and extract the data\n",
        "for row in results:\n",
        "  print(row) # process the row data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gipQ5nxvSXGL",
        "outputId": "b4492ddd-e06c-4dfa-c1ec-c35d82c29c50"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Row((3757, 3115, 134067, datetime.datetime(2139, 2, 13, 3, 11), datetime.datetime(2139, 2, 20, 7, 33), None, 'EMERGENCY', 'EMERGENCY ROOM ADMIT', 'SNF', 'Medicare', None, None, None, 'WHITE', datetime.datetime(2139, 2, 13, 0, 2), datetime.datetime(2139, 2, 13, 3, 22), 'STAB WOUND', 0, 1), {'ROW_ID': 0, 'SUBJECT_ID': 1, 'HADM_ID': 2, 'ADMITTIME': 3, 'DISCHTIME': 4, 'DEATHTIME': 5, 'ADMISSION_TYPE': 6, 'ADMISSION_LOCATION': 7, 'DISCHARGE_LOCATION': 8, 'INSURANCE': 9, 'LANGUAGE': 10, 'RELIGION': 11, 'MARITAL_STATUS': 12, 'ETHNICITY': 13, 'EDREGTIME': 14, 'EDOUTTIME': 15, 'DIAGNOSIS': 16, 'HOSPITAL_EXPIRE_FLAG': 17, 'HAS_CHARTEVENTS_DATA': 18})\n",
            "Row((8689, 7124, 109129, datetime.datetime(2188, 7, 11, 0, 58), datetime.datetime(2188, 8, 1, 12, 4), None, 'EMERGENCY', 'EMERGENCY ROOM ADMIT', 'SNF', 'Medicare', None, None, None, 'WHITE', datetime.datetime(2188, 7, 10, 14, 17), datetime.datetime(2188, 7, 11, 1, 52), 'PENILE LACERATION-CELLULITIS', 0, 1), {'ROW_ID': 0, 'SUBJECT_ID': 1, 'HADM_ID': 2, 'ADMITTIME': 3, 'DISCHTIME': 4, 'DEATHTIME': 5, 'ADMISSION_TYPE': 6, 'ADMISSION_LOCATION': 7, 'DISCHARGE_LOCATION': 8, 'INSURANCE': 9, 'LANGUAGE': 10, 'RELIGION': 11, 'MARITAL_STATUS': 12, 'ETHNICITY': 13, 'EDREGTIME': 14, 'EDOUTTIME': 15, 'DIAGNOSIS': 16, 'HOSPITAL_EXPIRE_FLAG': 17, 'HAS_CHARTEVENTS_DATA': 18})\n",
            "Row((12652, 10348, 121510, datetime.datetime(2133, 4, 16, 21, 12), datetime.datetime(2133, 4, 23, 15, 52), None, 'EMERGENCY', 'EMERGENCY ROOM ADMIT', 'SNF', 'Medicare', None, None, None, 'UNKNOWN/NOT SPECIFIED', datetime.datetime(2133, 4, 16, 19, 22), datetime.datetime(2133, 4, 16, 22, 17), 'STATUS EPILEPTICUS', 0, 1), {'ROW_ID': 0, 'SUBJECT_ID': 1, 'HADM_ID': 2, 'ADMITTIME': 3, 'DISCHTIME': 4, 'DEATHTIME': 5, 'ADMISSION_TYPE': 6, 'ADMISSION_LOCATION': 7, 'DISCHARGE_LOCATION': 8, 'INSURANCE': 9, 'LANGUAGE': 10, 'RELIGION': 11, 'MARITAL_STATUS': 12, 'ETHNICITY': 13, 'EDREGTIME': 14, 'EDOUTTIME': 15, 'DIAGNOSIS': 16, 'HOSPITAL_EXPIRE_FLAG': 17, 'HAS_CHARTEVENTS_DATA': 18})\n",
            "Row((11501, 9396, 106469, datetime.datetime(2109, 2, 16, 23, 14), datetime.datetime(2109, 2, 23, 12, 1), None, 'EMERGENCY', 'EMERGENCY ROOM ADMIT', 'SNF', 'Medicare', None, None, None, 'WHITE', datetime.datetime(2109, 2, 16, 20, 58), datetime.datetime(2109, 2, 16, 23, 42), 'SUBDURAL HEMATOMA', 0, 1), {'ROW_ID': 0, 'SUBJECT_ID': 1, 'HADM_ID': 2, 'ADMITTIME': 3, 'DISCHTIME': 4, 'DEATHTIME': 5, 'ADMISSION_TYPE': 6, 'ADMISSION_LOCATION': 7, 'DISCHARGE_LOCATION': 8, 'INSURANCE': 9, 'LANGUAGE': 10, 'RELIGION': 11, 'MARITAL_STATUS': 12, 'ETHNICITY': 13, 'EDREGTIME': 14, 'EDOUTTIME': 15, 'DIAGNOSIS': 16, 'HOSPITAL_EXPIRE_FLAG': 17, 'HAS_CHARTEVENTS_DATA': 18})\n",
            "Row((11419, 9333, 133732, datetime.datetime(2167, 10, 6, 18, 35), datetime.datetime(2167, 10, 16, 13, 13), None, 'URGENT', 'TRANSFER FROM HOSP/EXTRAM', 'SNF', 'Private', None, None, None, 'UNKNOWN/NOT SPECIFIED', None, None, 'CORONARY ARTERY DISEASE', 0, 1), {'ROW_ID': 0, 'SUBJECT_ID': 1, 'HADM_ID': 2, 'ADMITTIME': 3, 'DISCHTIME': 4, 'DEATHTIME': 5, 'ADMISSION_TYPE': 6, 'ADMISSION_LOCATION': 7, 'DISCHARGE_LOCATION': 8, 'INSURANCE': 9, 'LANGUAGE': 10, 'RELIGION': 11, 'MARITAL_STATUS': 12, 'ETHNICITY': 13, 'EDREGTIME': 14, 'EDOUTTIME': 15, 'DIAGNOSIS': 16, 'HOSPITAL_EXPIRE_FLAG': 17, 'HAS_CHARTEVENTS_DATA': 18})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connect to Google Cloud Storage (GCS) to access the chest x-rays\n",
        "We will plan to access the images directly from GCS vs. uploading them. This section will access the GCS bucket to process the images.\n",
        "\n",
        "This section will assume that you have already authenticated with Google Cloud from the prior step using auth.authenticate_user()"
      ],
      "metadata": {
        "id": "SU68V9Kzc48-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install relevant libraries\n",
        "from google.cloud import storage\n",
        "\n",
        "# Create a client\n",
        "project_id = 'mimic-iv-390722'\n",
        "storage_client = storage.Client(project=project_id)\n",
        "\n",
        "# Get a bucket reference\n",
        "bucket_name = 'mimic-iv-cxr'\n",
        "bucket = storage_client.get_bucket(bucket_name)\n",
        "\n",
        "# List objects in the bucket\n",
        "blobs = bucket.list_blobs()\n",
        "\n",
        "# Set paths to files\n",
        "# files_path =\n",
        "\n",
        "# Alternatively, you can directly access a specific blob by its name\n",
        "specific_blob = bucket.blob('files/p10/p10000032/s50414267/02aa804e-bde0afdd-112c0b34-7bc16630-4e384014.jpg')\n",
        "print(specific_blob)\n",
        "# Perform operations on the specific blob\n",
        "# For example, download the file\n",
        "#specific_blob.download_to_filename('local_file.jpg')\n",
        "#print(\"File downloaded successfully.\")\n",
        "#for blob in blobs:\n",
        "#  print(blob.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnHW3QQHdFiQ",
        "outputId": "5d4633a7-b8ec-4d87-8c90-a8579897d870"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Blob: mimic-iv-cxr, files/p10/p10000032/s50414267/02aa804e-bde0afdd-112c0b34-7bc16630-4e384014.jpg, None>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Explore the data\n",
        "Once everything is setup. We can start to run some queries to get an idea of what the dataset looks like. We'll start with some queries that profile the MIMIC-III dataset.\n",
        "\n",
        "In this section, we'll also define some helper functions that will assist us in querying the data.\n",
        "\n",
        "A examplar notebook for exploring the data will be primarily based on the [MIMIC code repository](https://github.com/MIT-LCP/mimic-code/blob/main/mimic-iv/notebooks/tableone.ipynb) for doing just that - exploring demographics and charts within MIMIC-IV."
      ],
      "metadata": {
        "id": "Sedw77J6Vt2X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install tableone\n",
        "# from tableone import TableOne"
      ],
      "metadata": {
        "id": "r6aG1UQmhezZ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import relevant libraries for exploration\n",
        "from collections import OrderedDict\n",
        "from tabulate import tabulate\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "_O3pGnsvhT-7"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define helper functions\n",
        "def query_dataset(query):\n",
        "  # Run the query\n",
        "  query_job = client.query(query)\n",
        "\n",
        "  # Get the results\n",
        "  results = query_job.result()\n",
        "\n",
        "  # Process and extract the data\n",
        "  for row in results:\n",
        "    print(row) # process the row data\n",
        "\n",
        "def create_query(dataset, table):\n",
        "  project = 'physionet-data'\n",
        "  query = \"\"\"\n",
        "  SELECT *\n",
        "  FROM `{0}.{1}.{2}`\n",
        "  LIMIT 3\n",
        "  \"\"\".format(project, dataset, table)\n",
        "  return query\n",
        "\n",
        "def summarize_data(dataset, table):\n",
        "    # Run the query to retrieve the data\n",
        "    query = \"\"\"\n",
        "    SELECT *\n",
        "    FROM `{0}.{1}.{2}`\n",
        "    \"\"\".format('physionet-data', dataset, table)\n",
        "\n",
        "    query_job = client.query(query)\n",
        "    results = query_job.result()\n",
        "\n",
        "    # Initialize counters and dictionaries\n",
        "    total_patients = 0\n",
        "    distinct_patients = set()\n",
        "    disease_counts = {}\n",
        "    disease_percentages = {}\n",
        "\n",
        "    # Process and extract the data\n",
        "    for row in results:\n",
        "        total_patients += 1\n",
        "        distinct_patients.add(row.subject_id)\n",
        "\n",
        "        # Iterate over the diseases/findings columns\n",
        "        for column_name in row.keys():\n",
        "            if column_name not in ['subject_id', 'study_id']:\n",
        "                disease_value = row[column_name]\n",
        "\n",
        "                # Count the occurrences of each disease/finding\n",
        "                if disease_value is not None:\n",
        "                    if column_name not in disease_counts:\n",
        "                        disease_counts[column_name] = 0\n",
        "                    disease_counts[column_name] += 1\n",
        "\n",
        "    # Calculate the percentages of each disease/finding\n",
        "    for column_name, count in disease_counts.items():\n",
        "        percentage = (count / total_patients) * 100\n",
        "        disease_percentages[column_name] = percentage\n",
        "\n",
        "    # Prepare the summary statistics as a list of lists\n",
        "    summary_data = [\n",
        "        [\"Total count of patients:\", total_patients],\n",
        "        [\"Count of distinct patients:\", len(distinct_patients)],\n",
        "        [\"Count of each disease/finding (from most frequent to least frequent):\"]\n",
        "    ]\n",
        "    for column_name, count in sorted(disease_counts.items(), key=lambda x: x[1], reverse=True):\n",
        "        summary_data.append([column_name, count])\n",
        "    summary_data.append([\"Percentage of each disease/finding to the total count of patients:\"])\n",
        "    for column_name, percentage in sorted(disease_percentages.items(), key=lambda x: x[1], reverse=True):\n",
        "        summary_data.append([column_name, \"{:.2f}%\".format(percentage)])\n",
        "\n",
        "    # Generate the formatted table\n",
        "    table_output = tabulate(summary_data, headers=[\"Category\", \"Count/Percentage\"], tablefmt=\"github\")\n",
        "\n",
        "    # Print the formatted table\n",
        "    print(table_output)\n",
        "\n",
        "# Define the dataset and table of interest\n",
        "dataset = 'mimic_cxr'\n",
        "table = 'chexpert'\n",
        "\n",
        "# Create query\n",
        "# query = create_query(dataset, table)\n",
        "# query_dataset(query)\n",
        "\n",
        "# Summarize findings\n",
        "summarize_data(dataset, table)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzt9hZD0V6q2",
        "outputId": "cef5cb59-7a17-4fe7-f585-84cf2280c251"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| Category                                                              | Count/Percentage   |\n",
            "|-----------------------------------------------------------------------|--------------------|\n",
            "| Total count of patients:                                              | 227827             |\n",
            "| Count of distinct patients:                                           | 65379              |\n",
            "| Count of each disease/finding (from most frequent to least frequent): |                    |\n",
            "| Pleural_Effusion                                                      | 87272              |\n",
            "| No_Finding                                                            | 75455              |\n",
            "| Support_Devices                                                       | 70281              |\n",
            "| Cardiomegaly                                                          | 66799              |\n",
            "| Edema                                                                 | 65833              |\n",
            "| Pneumonia                                                             | 59185              |\n",
            "| Lung_Opacity                                                          | 58425              |\n",
            "| Atelectasis                                                           | 57666              |\n",
            "| Pneumothorax                                                          | 53848              |\n",
            "| Consolidation                                                         | 23076              |\n",
            "| Enlarged_Cardiomediastinum                                            | 21837              |\n",
            "| Lung_Lesion                                                           | 8287               |\n",
            "| Fracture                                                              | 5831               |\n",
            "| Pleural_Other                                                         | 2902               |\n",
            "| Percentage of each disease/finding to the total count of patients:    |                    |\n",
            "| Pleural_Effusion                                                      | 38.31%             |\n",
            "| No_Finding                                                            | 33.12%             |\n",
            "| Support_Devices                                                       | 30.85%             |\n",
            "| Cardiomegaly                                                          | 29.32%             |\n",
            "| Edema                                                                 | 28.90%             |\n",
            "| Pneumonia                                                             | 25.98%             |\n",
            "| Lung_Opacity                                                          | 25.64%             |\n",
            "| Atelectasis                                                           | 25.31%             |\n",
            "| Pneumothorax                                                          | 23.64%             |\n",
            "| Consolidation                                                         | 10.13%             |\n",
            "| Enlarged_Cardiomediastinum                                            | 9.58%              |\n",
            "| Lung_Lesion                                                           | 3.64%              |\n",
            "| Fracture                                                              | 2.56%              |\n",
            "| Pleural_Other                                                         | 1.27%              |\n"
          ]
        }
      ]
    }
  ]
}