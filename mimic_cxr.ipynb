{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMMU8KlX3F5FvUkk8U7FGXb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ufbfung/mimic/blob/main/mimic_cxr.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MIMIC-CXR\n",
        "This notebook will explore the new chest x-ray repository from mimic."
      ],
      "metadata": {
        "id": "-GyAK6-2cLzA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup environment\n"
      ],
      "metadata": {
        "id": "HDTXEIyuRWBt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mount Google Drive & Map File Paths\n",
        "This section will connect to your google drive and define any file paths for subsequent access and references."
      ],
      "metadata": {
        "id": "edfS7hn6GQdl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import relevant libraries\n",
        "from google.colab import drive # to mount google drive\n",
        "import os # to deal with file paths\n",
        "import numpy as np # to deal with data\n",
        "import pandas as pd # to deal with data\n",
        "import cv2 # to read videos\n",
        "from matplotlib import pyplot as plt # to plot figures\n",
        "\n",
        "# Mount drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "6KXtibdpGPVk",
        "outputId": "48bb82fc-f2c1-4650-b583-5cfae946c0fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define file paths\n",
        "root_path = '/content/drive/My Drive/coding/mimic/cxr'\n",
        "train_split_csv = os.path.join(root_path, 'mimic-cxr-2.0.0-split.csv')"
      ],
      "metadata": {
        "id": "eqZj-2BXG4Jp"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the CSV file into a dataframe\n",
        "split = pd.read_csv(train_split_csv)\n",
        "\n",
        "# Summarize the values in the 'split' column\n",
        "split_summary = split['split'].value_counts()\n",
        "\n",
        "# Display the summary\n",
        "print(split_summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Ts4uHsyKXfK",
        "outputId": "61036ddf-8d27-4045-d78b-08ccca395c83"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train       368960\n",
            "test          5159\n",
            "validate      2991\n",
            "Name: split, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print first few rows of csv\n",
        "print(split.head)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1APHoR6gLqhv",
        "outputId": "a6c09a2a-38ee-4291-bf69-59d9bbae740c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<bound method NDFrame.head of                                             dicom_id  study_id  subject_id  \\\n",
            "0       02aa804e-bde0afdd-112c0b34-7bc16630-4e384014  50414267    10000032   \n",
            "1       174413ec-4ec4c1f7-34ea26b7-c5f994f8-79ef1962  50414267    10000032   \n",
            "2       2a2277a9-b0ded155-c0de8eb9-c124d10e-82c5caab  53189527    10000032   \n",
            "3       e084de3b-be89b11e-20fe3f9f-9c8d8dfe-4cfd202c  53189527    10000032   \n",
            "4       68b5c4b1-227d0485-9cc38c3f-7b84ab51-4b472714  53911762    10000032   \n",
            "...                                              ...       ...         ...   \n",
            "377105  428e2c18-5721d8f3-35a05001-36f3d080-9053b83c  57132437    19999733   \n",
            "377106  58c403aa-35ff8bd9-73e39f54-8dc9cc5d-e0ec3fa9  57132437    19999733   \n",
            "377107  58766883-376a15ce-3b323a28-6af950a0-16b793bd  55368167    19999987   \n",
            "377108  7ba273af-3d290f8d-e28d0ab4-484b7a86-7fc12b08  58621812    19999987   \n",
            "377109  1a1fe7e3-cbac5d93-b339aeda-86bb86b5-4f31e82e  58971208    19999987   \n",
            "\n",
            "        split  \n",
            "0       train  \n",
            "1       train  \n",
            "2       train  \n",
            "3       train  \n",
            "4       train  \n",
            "...       ...  \n",
            "377105  train  \n",
            "377106  train  \n",
            "377107  train  \n",
            "377108  train  \n",
            "377109  train  \n",
            "\n",
            "[377110 rows x 4 columns]>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Integrate with BigQuery\n",
        "This section will allow integration with Google BigQuery to bring data into your Colab instance."
      ],
      "metadata": {
        "id": "0ll_P10pSieZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Authenticate and authorize Colab Notebook\n",
        "This step will install relevant libraries for authentication and authorization and also authenticate your Colab notebook to connect to Google BigQuery."
      ],
      "metadata": {
        "id": "NtLwOkhjRswa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install relevant libraries\n",
        "from google.colab import auth\n",
        "\n",
        "# Authenticate\n",
        "auth.authenticate_user()\n",
        "\n",
        "# Install relevant library\n",
        "from google.cloud import bigquery\n",
        "\n",
        "# Define project you're interested in querying from BigQuery\n",
        "project = 'mimic-iv-390722'\n",
        "\n",
        "# Create a client\n",
        "client = bigquery.Client(project=project)\n",
        "\n",
        "# Write a sample query to check connection\n",
        "query = \"\"\"\n",
        "SELECT *\n",
        "FROM `physionet-data.mimiciii_clinical.admissions`\n",
        "LIMIT 1\n",
        "\"\"\"\n",
        "\n",
        "# Run the query\n",
        "query_job = client.query(query)\n",
        "\n",
        "# Get the results\n",
        "results = query_job.result()\n",
        "\n",
        "# Process and extract the data\n",
        "for row in results:\n",
        "  print(row) # process the row data"
      ],
      "metadata": {
        "id": "huYUmwPZRwlX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "520676a5-1ef9-45f5-9d40-053d337d6782"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Row((3757, 3115, 134067, datetime.datetime(2139, 2, 13, 3, 11), datetime.datetime(2139, 2, 20, 7, 33), None, 'EMERGENCY', 'EMERGENCY ROOM ADMIT', 'SNF', 'Medicare', None, None, None, 'WHITE', datetime.datetime(2139, 2, 13, 0, 2), datetime.datetime(2139, 2, 13, 3, 22), 'STAB WOUND', 0, 1), {'ROW_ID': 0, 'SUBJECT_ID': 1, 'HADM_ID': 2, 'ADMITTIME': 3, 'DISCHTIME': 4, 'DEATHTIME': 5, 'ADMISSION_TYPE': 6, 'ADMISSION_LOCATION': 7, 'DISCHARGE_LOCATION': 8, 'INSURANCE': 9, 'LANGUAGE': 10, 'RELIGION': 11, 'MARITAL_STATUS': 12, 'ETHNICITY': 13, 'EDREGTIME': 14, 'EDOUTTIME': 15, 'DIAGNOSIS': 16, 'HOSPITAL_EXPIRE_FLAG': 17, 'HAS_CHARTEVENTS_DATA': 18})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connect to Google Cloud Storage (GCS) to access the chest x-rays\n",
        "We will plan to access the images directly from GCS vs. uploading them. This section will access the GCS bucket to process the images.\n",
        "\n",
        "This section will assume that you have already authenticated with Google Cloud from the prior step using auth.authenticate_user()"
      ],
      "metadata": {
        "id": "SU68V9Kzc48-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install relevant libraries\n",
        "from google.cloud import storage\n",
        "\n",
        "# Create a client\n",
        "project_id = 'mimic-iv-390722'\n",
        "storage_client = storage.Client(project=project_id)\n",
        "\n",
        "# Get a bucket reference\n",
        "bucket_name = 'mimic-iv-cxr'\n",
        "bucket = storage_client.get_bucket(bucket_name)\n",
        "\n",
        "# List objects in the bucket\n",
        "blobs = bucket.list_blobs()\n",
        "\n",
        "# Set paths to files\n",
        "# files_path =\n",
        "\n",
        "# Alternatively, you can directly access a specific blob by its name\n",
        "specific_blob = bucket.blob('files/p10/p10000032/s50414267/02aa804e-bde0afdd-112c0b34-7bc16630-4e384014.jpg')\n",
        "print(specific_blob)\n",
        "# Perform operations on the specific blob\n",
        "# For example, download the file\n",
        "#specific_blob.download_to_filename('local_file.jpg')\n",
        "#print(\"File downloaded successfully.\")\n",
        "#for blob in blobs:\n",
        "#  print(blob.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnHW3QQHdFiQ",
        "outputId": "5d4633a7-b8ec-4d87-8c90-a8579897d870"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Blob: mimic-iv-cxr, files/p10/p10000032/s50414267/02aa804e-bde0afdd-112c0b34-7bc16630-4e384014.jpg, None>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download metadata files from mimic_cxr as csv files\n",
        "This section will download key metadata files as csvs into your working directory for further processing. Specifically, it will do the following:\n",
        "- Query and download the chexpert table from mimic_cxr dataset\n",
        "- Query and download the record_list table from mimic_cxr dataset\n",
        "- Join chexpert and record_list on study_id to get the specific path of where each image is located.\n",
        "\n",
        "The purpose of this section is to allow querying of specific labels of interest from chexpert (e.g. pneumonia) and retrieve all the image paths associated with that label for further investigation and modeling."
      ],
      "metadata": {
        "id": "WBcgXgq6p1lu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Define helper functions that will assist in the extraction\n",
        "These are the functions that will perform the extraction. These will eventually be moved into a utils program."
      ],
      "metadata": {
        "id": "5ndAIHGirHFM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def export_table(dataset, table, output_file=None):\n",
        "    # Set the default output file name if not provided\n",
        "    if output_file is None:\n",
        "        output_file = f\"{table}.csv\"\n",
        "\n",
        "    # Create the query to fetch the entire table\n",
        "    query = create_query(dataset, table)\n",
        "\n",
        "    # Execute the query and get the results\n",
        "    results = query_dataset(query)\n",
        "\n",
        "    # Convert the results to a Pandas DataFrame\n",
        "    results_df = pd.DataFrame(results)\n",
        "\n",
        "    # Save the DataFrame to a CSV file\n",
        "    results_df.to_csv(output_file, index=False)\n",
        "\n",
        "    print(f\"Exported {table} table to {output_file}.\")\n",
        "\n",
        "def query_dataset(query):\n",
        "  # Run the query\n",
        "    query_job = client.query(query)\n",
        "\n",
        "    # Get the results\n",
        "    results = query_job.result()\n",
        "\n",
        "    # Convert the results to a list of dictionaries\n",
        "    results_list = [dict(row.items()) for row in results]\n",
        "\n",
        "    return results_list\n",
        "\n",
        "def create_query(dataset, table):\n",
        "  project = 'physionet-data'\n",
        "  query = \"\"\"\n",
        "  SELECT *\n",
        "  FROM `{0}.{1}.{2}`\n",
        "  \"\"\".format(project, dataset, table)\n",
        "  return query\n",
        "\n",
        "def extract_labeled_rows(dataframe, column, default_value=1.0):\n",
        "    # Filter the rows based on the specified column and default value\n",
        "    filtered_rows = dataframe[(dataframe[column] == default_value)]\n",
        "\n",
        "    return filtered_rows\n",
        "\n",
        "def summarize_output(dataframe):\n",
        "    # Tally the number of total images found\n",
        "    total_images = dataframe.shape[0]\n",
        "\n",
        "    # Tally the number of unique patients represented by subject_id_x\n",
        "    unique_patients = dataframe['subject_id_x'].nunique()\n",
        "\n",
        "    # Tally the number of unique studies by study_id\n",
        "    unique_studies = dataframe['study_id'].nunique()\n",
        "\n",
        "    # Create a dictionary to store the summary\n",
        "    summary = {\n",
        "        'Total Images': total_images,\n",
        "        'Unique Patients': unique_patients,\n",
        "        'Unique Studies': unique_studies\n",
        "    }\n",
        "\n",
        "    return summary"
      ],
      "metadata": {
        "id": "SwSmAVT5M19E"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define dataset\n",
        "dataset = 'mimic_cxr'\n",
        "\n",
        "# Download the full chexpert table as a csv\n",
        "print('Downloading chexpert table...')\n",
        "# export_table(dataset, 'chexpert') # Only need to run once\n",
        "print('Downloading chexpert table complete')\n",
        "\n",
        "# Download the full record_list table as a csv\n",
        "print('Downloading record_list table...')\n",
        "# export_table(dataset, 'record_list') # Only need to run once\n",
        "print('Downloading record_list table complete')\n",
        "\n",
        "# Read both csvs into dataframes\n",
        "chexpert_csv = pd.read_csv('chexpert.csv')\n",
        "record_list_csv = pd.read_csv('record_list.csv')\n",
        "\n",
        "# Print number of rows for each\n",
        "print(\"Number of rows in chexpert_csv:\", chexpert_csv.shape[0])\n",
        "print(\"Number of rows in record_list_csv:\", record_list_csv.shape[0])\n",
        "\n",
        "# Join the two csv tables\n",
        "joined_df = chexpert_csv.merge(record_list_csv, on='study_id', how='inner')\n",
        "\n",
        "# Filtered columns\n",
        "filtered_columns = ['subject_id_x', 'subject_id_y', 'study_id', 'dicom_id', 'path', 'Lung_Lesion', 'Pneumonia']\n",
        "\n",
        "# Define label of interest\n",
        "label = 'Pneumonia'\n",
        "\n",
        "# Extract labeled rows\n",
        "interest_df = extract_labeled_rows(joined_df, label)\n",
        "\n",
        "# Call the summarize_output function\n",
        "summary = summarize_output(interest_df)\n",
        "\n",
        "# Print the summary\n",
        "print(summary)"
      ],
      "metadata": {
        "id": "YxOYJwj6qxiH",
        "outputId": "4ebe2e40-6498-4ae9-8455-3f51ede28cde",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading chexpert table...\n",
            "Downloading chexpert table complete\n",
            "Downloading record_list table...\n",
            "Downloading record_list table complete\n",
            "Number of rows in chexpert_csv: 227827\n",
            "Number of rows in record_list_csv: 377110\n",
            "{'Total Images': 26222, 'Unique Patients': 10355, 'Unique Studies': 16556}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup ResNet CNN\n",
        "- For the training-validate-test splits, we'll use the predefined studies set by mimic in their mimic-cxr-2.0.0-split.csv"
      ],
      "metadata": {
        "id": "usBqzE4ZFty1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#"
      ],
      "metadata": {
        "id": "yPSXGYYdF0Lo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Explore the data\n",
        "Once everything is setup. We can start to run some queries to get an idea of what the dataset looks like. We'll start with some queries that profile the MIMIC-III dataset.\n",
        "\n",
        "In this section, we'll also define some helper functions that will assist us in querying the data.\n",
        "\n",
        "A examplar notebook for exploring the data will be primarily based on the [MIMIC code repository](https://github.com/MIT-LCP/mimic-code/blob/main/mimic-iv/notebooks/tableone.ipynb) for doing just that - exploring demographics and charts within MIMIC-IV."
      ],
      "metadata": {
        "id": "Sedw77J6Vt2X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install tableone\n",
        "# from tableone import TableOne"
      ],
      "metadata": {
        "id": "r6aG1UQmhezZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import relevant libraries for exploration\n",
        "from collections import OrderedDict\n",
        "from tabulate import tabulate\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "_O3pGnsvhT-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_data(dataset, table):\n",
        "    # Run the query to retrieve the data\n",
        "    query = \"\"\"\n",
        "    SELECT *\n",
        "    FROM `{0}.{1}.{2}`\n",
        "    \"\"\".format('physionet-data', dataset, table)\n",
        "\n",
        "    query_job = client.query(query)\n",
        "    results = query_job.result()\n",
        "\n",
        "    # Initialize counters and dictionaries\n",
        "    total_patients = 0\n",
        "    distinct_patients = set()\n",
        "    disease_counts = {}\n",
        "    disease_percentages = {}\n",
        "\n",
        "    # Process and extract the data\n",
        "    for row in results:\n",
        "        total_patients += 1\n",
        "        distinct_patients.add(row.subject_id)\n",
        "\n",
        "        # Iterate over the diseases/findings columns\n",
        "        for column_name in row.keys():\n",
        "            if column_name not in ['subject_id', 'study_id']:\n",
        "                disease_value = row[column_name]\n",
        "\n",
        "                # Count the occurrences of each disease/finding\n",
        "                if disease_value is not None:\n",
        "                    if column_name not in disease_counts:\n",
        "                        disease_counts[column_name] = 0\n",
        "                    disease_counts[column_name] += 1\n",
        "\n",
        "    # Calculate the percentages of each disease/finding\n",
        "    for column_name, count in disease_counts.items():\n",
        "        percentage = (count / total_patients) * 100\n",
        "        disease_percentages[column_name] = percentage\n",
        "\n",
        "    # Prepare the summary statistics as a list of lists\n",
        "    summary_data = [\n",
        "        [\"Total count of patients:\", total_patients],\n",
        "        [\"Count of distinct patients:\", len(distinct_patients)],\n",
        "        [\"Count of each disease/finding (from most frequent to least frequent):\"]\n",
        "    ]\n",
        "    for column_name, count in sorted(disease_counts.items(), key=lambda x: x[1], reverse=True):\n",
        "        summary_data.append([column_name, count])\n",
        "    summary_data.append([\"Percentage of each disease/finding to the total count of patients:\"])\n",
        "    for column_name, percentage in sorted(disease_percentages.items(), key=lambda x: x[1], reverse=True):\n",
        "        summary_data.append([column_name, \"{:.2f}%\".format(percentage)])\n",
        "\n",
        "    # Generate the formatted table\n",
        "    table_output = tabulate(summary_data, headers=[\"Category\", \"Count/Percentage\"], tablefmt=\"github\")\n",
        "\n",
        "    # Print the formatted table\n",
        "    print(table_output)\n",
        "\n",
        "# Define the dataset and table of interest\n",
        "dataset = 'mimic_cxr'\n",
        "table = 'chexpert'\n",
        "\n",
        "# Create query\n",
        "# query = create_query(dataset, table)\n",
        "# query_dataset(query)\n",
        "\n",
        "# Summarize findings\n",
        "summarize_data(dataset, table)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzt9hZD0V6q2",
        "outputId": "cef5cb59-7a17-4fe7-f585-84cf2280c251"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| Category                                                              | Count/Percentage   |\n",
            "|-----------------------------------------------------------------------|--------------------|\n",
            "| Total count of patients:                                              | 227827             |\n",
            "| Count of distinct patients:                                           | 65379              |\n",
            "| Count of each disease/finding (from most frequent to least frequent): |                    |\n",
            "| Pleural_Effusion                                                      | 87272              |\n",
            "| No_Finding                                                            | 75455              |\n",
            "| Support_Devices                                                       | 70281              |\n",
            "| Cardiomegaly                                                          | 66799              |\n",
            "| Edema                                                                 | 65833              |\n",
            "| Pneumonia                                                             | 59185              |\n",
            "| Lung_Opacity                                                          | 58425              |\n",
            "| Atelectasis                                                           | 57666              |\n",
            "| Pneumothorax                                                          | 53848              |\n",
            "| Consolidation                                                         | 23076              |\n",
            "| Enlarged_Cardiomediastinum                                            | 21837              |\n",
            "| Lung_Lesion                                                           | 8287               |\n",
            "| Fracture                                                              | 5831               |\n",
            "| Pleural_Other                                                         | 2902               |\n",
            "| Percentage of each disease/finding to the total count of patients:    |                    |\n",
            "| Pleural_Effusion                                                      | 38.31%             |\n",
            "| No_Finding                                                            | 33.12%             |\n",
            "| Support_Devices                                                       | 30.85%             |\n",
            "| Cardiomegaly                                                          | 29.32%             |\n",
            "| Edema                                                                 | 28.90%             |\n",
            "| Pneumonia                                                             | 25.98%             |\n",
            "| Lung_Opacity                                                          | 25.64%             |\n",
            "| Atelectasis                                                           | 25.31%             |\n",
            "| Pneumothorax                                                          | 23.64%             |\n",
            "| Consolidation                                                         | 10.13%             |\n",
            "| Enlarged_Cardiomediastinum                                            | 9.58%              |\n",
            "| Lung_Lesion                                                           | 3.64%              |\n",
            "| Fracture                                                              | 2.56%              |\n",
            "| Pleural_Other                                                         | 1.27%              |\n"
          ]
        }
      ]
    }
  ]
}