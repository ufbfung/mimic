{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMDlOQxyViPlWLXIxottZt1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ufbfung/mimic/blob/main/exploration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MIMIC-III Dataset\n",
        "Access to the MIMIC-III dataset can be found at PhysioNet website (https://physionet.org/content/mimiciii/1.4/).\n",
        "\n",
        "Freely available for non-commercial research purposes, but requires approval.\n",
        "\n",
        "# MIMIC-IV Dataset\n",
        "Copied directly from [Physionet MIMIC-IV](https://physionet.org/content/mimiciv/2.2/)\n",
        "\n",
        "## Abstract\n",
        "Retrospectively collected medical data has the opportunity to improve patient care through knowledge discovery and algorithm development. Broad reuse of medical data is desirable for the greatest public good, but data sharing must be done in a manner which protects patient privacy. The Medical Information Mart for Intensive Care (MIMIC)-III database provided critical care data for over 40,000 patients admitted to intensive care units at the Beth Israel Deaconess Medical Center (BIDMC). Importantly, MIMIC-III was deidentified, and patient identifiers were removed according to the Health Insurance Portability and Accountability Act (HIPAA) Safe Harbor provision. MIMIC-III has been integral in driving large amounts of research in clinical informatics, epidemiology, and machine learning. Here we present MIMIC-IV, an update to MIMIC-III, which incorporates contemporary data and improves on numerous aspects of MIMIC-III. MIMIC-IV adopts a modular approach to data organization, highlighting data provenance and facilitating both individual and combined use of disparate data sources. MIMIC-IV is intended to carry on the success of MIMIC-III and support a broad set of applications within healthcare.\n",
        "\n",
        "## Background\n",
        "In recent years there has been a concerted move towards the adoption of digital health record systems in hospitals. In the US, nearly 96% of hospitals had a digital electronic health record system (EHR) in 2015 [1]. Retrospectively collected medical data has increasingly been used for epidemiology and predictive modeling. The latter is in part due to the effectiveness of modeling approaches on large datasets [2]. Despite these advances, access to medical data to improve patient care remains a significant challenge. While the reasons for limited sharing of medical data are multifaceted, concerns around patient privacy are highlighted as one of the most significant issues. Although patient studies have shown almost uniform agreement that deidentified medical data should be used to improve medical practice, domain experts continue to debate the optimal mechanisms of doing so. Uniquely, the MIMIC-III database adopted a permissive access scheme which allowed for broad reuse of the data [3]. This mechanism has been successful in the wide use of MIMIC-III in a variety of studies ranging from assessment of treatment efficacy in well defined cohorts to prediction of key patient outcomes such as mortality. MIMIC-IV aims to carry on the success of MIMIC-III, with a number of changes to improve usability of the data and enable more research applications.\n",
        "\n",
        "## Methods\n",
        "MIMIC-IV is sourced from two in-hospital database systems: a custom hospital wide EHR and an ICU specific clinical information system. The creation of MIMIC-IV was carried out in three steps:\n",
        "\n",
        "- Acquisition. Data for patients who were admitted to the BIDMC emergency department or one of the intensive care units were extracted from the respective hospital databases. A master patient list was created which contained all medical record numbers corresponding to patients admitted to an ICU or the emergency department between 2008 - 2019. All source tables were filtered to only rows related to patients in the master patient list.\n",
        "- Preparation. The data were reorganized to better facilitate retrospective data analysis. This included the denormalization of tables, removal of audit trails, and reorganization into fewer tables. The aim of this process is to simplify retrospective analysis of the database. Importantly, data cleaning steps were not performed, to ensure the data reflects a real-world clinical dataset.\n",
        "- Deidentify. Patient identifiers as stipulated by HIPAA were removed. Patient identifiers were replaced using a random cipher, resulting in deidentified integer identifiers for patients, hospitalizations, and ICU stays. Structured data were filtered using look up tables and allow lists. If necessary, a free-text deidentification algorithm was applied to remove PHI from free-text. Finally, date and times were shifted randomly into the future using an offset measured in days. A single date shift was assigned to each subject_id. As a result, the data for a single patient are internally consistent. For example, if the time between two measures in the database was 4 hours in the raw data, then the calculated time difference in MIMIC-IV will also be 4 hours. Conversely, distinct patients are not temporally comparable. That is, two patients admitted in 2130 were not necessarily admitted in the same year.\n",
        "\n",
        "After these three steps were carried out, the database was exported to a character based comma delimited format.\n",
        "\n",
        "## Release Notes\n",
        "### MIMIC-IV v2.2\n",
        "MIMIC-IV v2.2 was released in January 2023. It added provider identifiers, imputed hadm_id for a number of rows in emar, and changed the subset of subject_id which are held out. Final row counts are available in the validation scripts published with the MIMIC Code Repository [6]. For clarity, after removal of the test set, the row counts are as follows:\n",
        "\n",
        "- patients: 299,712 (was 315,460 in v2.0)\n",
        "- admissions: 431,231 (was 454,324 in v2.0)\n",
        "- icustays: 73,181 (was 76,943 in v2.0)"
      ],
      "metadata": {
        "id": "jVRYprhTRT0Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup environment\n"
      ],
      "metadata": {
        "id": "HDTXEIyuRWBt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load environment variables\n",
        "This section is just a template for future querying. Not used currently."
      ],
      "metadata": {
        "id": "fRu7vpcpRchv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "# Load variables from .env file\n",
        "load_dotenv('credentials.env')\n",
        "\n",
        "# Access the variables\n",
        "username = os.getenv('mimic_username')\n",
        "password = os.getenv('mimic_password')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jj0K7WNyRiRf",
        "outputId": "5932c849-4dd1-4eb6-fa05-7e6b2b77dd42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Integrate with BigQuery\n",
        "This section will allow integration with Google BigQuery to bring data into your Colab instance."
      ],
      "metadata": {
        "id": "0ll_P10pSieZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Authenticate and authorize Colab Notebook\n",
        "This step will install relevant libraries for authentication and authorization and also authenticate your Colab notebook to connect to Google BigQuery."
      ],
      "metadata": {
        "id": "NtLwOkhjRswa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install relevant libraries\n",
        "from google.colab import auth # this provides functions for authenticating and authorizing your Google account within the Colab environment\n",
        "\n",
        "# Authenticate\n",
        "auth.authenticate_user() # this initiates the authentication process which will prompt you to authenticate your Google account. The purpose of this authentication is to allow your Colab notebook to access Google Cloud services, such as BigQuery, using your authorized account."
      ],
      "metadata": {
        "id": "huYUmwPZRwlX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a client\n",
        "This step will create a client to access a specific project within BigQuery. You will want to copy the name of the project you're interested in querying from BigQuery and set it to the project variable."
      ],
      "metadata": {
        "id": "y43pP3aER1sc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install relevant library\n",
        "from google.cloud import bigquery\n",
        "\n",
        "# Define project you're interested in querying from BigQuery\n",
        "project = 'mimic-iv-390722'\n",
        "\n",
        "# Create a client\n",
        "client = bigquery.Client(project=project)"
      ],
      "metadata": {
        "id": "2Peri3gWR4y3"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Write a query\n",
        "This step involves writing an SQL query you want to use. Below is a simple query that can be used to quickly check the connection"
      ],
      "metadata": {
        "id": "z7BD6SJuSDOc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a sample query to check connection\n",
        "query = \"\"\"\n",
        "SELECT *\n",
        "FROM `physionet-data.mimiciii_clinical.admissions`\n",
        "LIMIT 5\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "vEW7e-ohSFpb"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run the query & get results\n"
      ],
      "metadata": {
        "id": "Bj3R0wkBSP_J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the query\n",
        "query_job = client.query(query)\n",
        "\n",
        "# Get the results\n",
        "results = query_job.result()"
      ],
      "metadata": {
        "id": "IizesHn9SSI8"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Process and extract the data\n",
        "This will process the data from the query and print them"
      ],
      "metadata": {
        "id": "TZeYkietSTaj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Process and extract the data\n",
        "for row in results:\n",
        "  print(row) # process the row data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gipQ5nxvSXGL",
        "outputId": "0743e5f7-5f3d-4ed2-8b06-d26b6dcf9ed6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Row((3757, 3115, 134067, datetime.datetime(2139, 2, 13, 3, 11), datetime.datetime(2139, 2, 20, 7, 33), None, 'EMERGENCY', 'EMERGENCY ROOM ADMIT', 'SNF', 'Medicare', None, None, None, 'WHITE', datetime.datetime(2139, 2, 13, 0, 2), datetime.datetime(2139, 2, 13, 3, 22), 'STAB WOUND', 0, 1), {'ROW_ID': 0, 'SUBJECT_ID': 1, 'HADM_ID': 2, 'ADMITTIME': 3, 'DISCHTIME': 4, 'DEATHTIME': 5, 'ADMISSION_TYPE': 6, 'ADMISSION_LOCATION': 7, 'DISCHARGE_LOCATION': 8, 'INSURANCE': 9, 'LANGUAGE': 10, 'RELIGION': 11, 'MARITAL_STATUS': 12, 'ETHNICITY': 13, 'EDREGTIME': 14, 'EDOUTTIME': 15, 'DIAGNOSIS': 16, 'HOSPITAL_EXPIRE_FLAG': 17, 'HAS_CHARTEVENTS_DATA': 18})\n",
            "Row((8689, 7124, 109129, datetime.datetime(2188, 7, 11, 0, 58), datetime.datetime(2188, 8, 1, 12, 4), None, 'EMERGENCY', 'EMERGENCY ROOM ADMIT', 'SNF', 'Medicare', None, None, None, 'WHITE', datetime.datetime(2188, 7, 10, 14, 17), datetime.datetime(2188, 7, 11, 1, 52), 'PENILE LACERATION-CELLULITIS', 0, 1), {'ROW_ID': 0, 'SUBJECT_ID': 1, 'HADM_ID': 2, 'ADMITTIME': 3, 'DISCHTIME': 4, 'DEATHTIME': 5, 'ADMISSION_TYPE': 6, 'ADMISSION_LOCATION': 7, 'DISCHARGE_LOCATION': 8, 'INSURANCE': 9, 'LANGUAGE': 10, 'RELIGION': 11, 'MARITAL_STATUS': 12, 'ETHNICITY': 13, 'EDREGTIME': 14, 'EDOUTTIME': 15, 'DIAGNOSIS': 16, 'HOSPITAL_EXPIRE_FLAG': 17, 'HAS_CHARTEVENTS_DATA': 18})\n",
            "Row((12652, 10348, 121510, datetime.datetime(2133, 4, 16, 21, 12), datetime.datetime(2133, 4, 23, 15, 52), None, 'EMERGENCY', 'EMERGENCY ROOM ADMIT', 'SNF', 'Medicare', None, None, None, 'UNKNOWN/NOT SPECIFIED', datetime.datetime(2133, 4, 16, 19, 22), datetime.datetime(2133, 4, 16, 22, 17), 'STATUS EPILEPTICUS', 0, 1), {'ROW_ID': 0, 'SUBJECT_ID': 1, 'HADM_ID': 2, 'ADMITTIME': 3, 'DISCHTIME': 4, 'DEATHTIME': 5, 'ADMISSION_TYPE': 6, 'ADMISSION_LOCATION': 7, 'DISCHARGE_LOCATION': 8, 'INSURANCE': 9, 'LANGUAGE': 10, 'RELIGION': 11, 'MARITAL_STATUS': 12, 'ETHNICITY': 13, 'EDREGTIME': 14, 'EDOUTTIME': 15, 'DIAGNOSIS': 16, 'HOSPITAL_EXPIRE_FLAG': 17, 'HAS_CHARTEVENTS_DATA': 18})\n",
            "Row((11501, 9396, 106469, datetime.datetime(2109, 2, 16, 23, 14), datetime.datetime(2109, 2, 23, 12, 1), None, 'EMERGENCY', 'EMERGENCY ROOM ADMIT', 'SNF', 'Medicare', None, None, None, 'WHITE', datetime.datetime(2109, 2, 16, 20, 58), datetime.datetime(2109, 2, 16, 23, 42), 'SUBDURAL HEMATOMA', 0, 1), {'ROW_ID': 0, 'SUBJECT_ID': 1, 'HADM_ID': 2, 'ADMITTIME': 3, 'DISCHTIME': 4, 'DEATHTIME': 5, 'ADMISSION_TYPE': 6, 'ADMISSION_LOCATION': 7, 'DISCHARGE_LOCATION': 8, 'INSURANCE': 9, 'LANGUAGE': 10, 'RELIGION': 11, 'MARITAL_STATUS': 12, 'ETHNICITY': 13, 'EDREGTIME': 14, 'EDOUTTIME': 15, 'DIAGNOSIS': 16, 'HOSPITAL_EXPIRE_FLAG': 17, 'HAS_CHARTEVENTS_DATA': 18})\n",
            "Row((11419, 9333, 133732, datetime.datetime(2167, 10, 6, 18, 35), datetime.datetime(2167, 10, 16, 13, 13), None, 'URGENT', 'TRANSFER FROM HOSP/EXTRAM', 'SNF', 'Private', None, None, None, 'UNKNOWN/NOT SPECIFIED', None, None, 'CORONARY ARTERY DISEASE', 0, 1), {'ROW_ID': 0, 'SUBJECT_ID': 1, 'HADM_ID': 2, 'ADMITTIME': 3, 'DISCHTIME': 4, 'DEATHTIME': 5, 'ADMISSION_TYPE': 6, 'ADMISSION_LOCATION': 7, 'DISCHARGE_LOCATION': 8, 'INSURANCE': 9, 'LANGUAGE': 10, 'RELIGION': 11, 'MARITAL_STATUS': 12, 'ETHNICITY': 13, 'EDREGTIME': 14, 'EDOUTTIME': 15, 'DIAGNOSIS': 16, 'HOSPITAL_EXPIRE_FLAG': 17, 'HAS_CHARTEVENTS_DATA': 18})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Explore the data\n",
        "Once everything is setup. We can start to run some queries to get an idea of what the dataset looks like. We'll start with some queries that profile the MIMIC-III dataset.\n",
        "\n",
        "In this section, we'll also define some helper functions that will assist us in querying the data.\n",
        "\n",
        "A examplar notebook for exploring the data will be primarily based on the [MIMIC code repository](https://github.com/MIT-LCP/mimic-code/blob/main/mimic-iv/notebooks/tableone.ipynb) for doing just that - exploring demographics and charts within MIMIC-IV."
      ],
      "metadata": {
        "id": "Sedw77J6Vt2X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tableone"
      ],
      "metadata": {
        "id": "r6aG1UQmhezZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import relevant libraries for exploration\n",
        "from collections import OrderedDict\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from tableone import TableOne"
      ],
      "metadata": {
        "id": "_O3pGnsvhT-7"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define helper functions\n",
        "def query_dataset(query):\n",
        "  # Run the query\n",
        "  query_job = client.query(query)\n",
        "\n",
        "  # Get the results\n",
        "  results = query_job.result()\n",
        "\n",
        "  # Process and extract the data\n",
        "  for row in results:\n",
        "    print(row) # process the row data\n",
        "\n",
        "def create_query(dataset, table):\n",
        "  project = 'physionet-data'\n",
        "  query = \"\"\"\n",
        "  SELECT *\n",
        "  FROM `{0}.{1}.{2}`\n",
        "  LIMIT 3\n",
        "  \"\"\".format(project, dataset, table)\n",
        "  return query\n",
        "\n",
        "# Define the dataset and table of interest\n",
        "dataset = 'mimiciii_clinical'\n",
        "table = 'admissions'\n",
        "\n",
        "query = create_query(dataset, table)\n",
        "\n",
        "query_dataset(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzt9hZD0V6q2",
        "outputId": "41e3b402-2c7a-408f-df11-018501f48515"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Row((3757, 3115, 134067, datetime.datetime(2139, 2, 13, 3, 11), datetime.datetime(2139, 2, 20, 7, 33), None, 'EMERGENCY', 'EMERGENCY ROOM ADMIT', 'SNF', 'Medicare', None, None, None, 'WHITE', datetime.datetime(2139, 2, 13, 0, 2), datetime.datetime(2139, 2, 13, 3, 22), 'STAB WOUND', 0, 1), {'ROW_ID': 0, 'SUBJECT_ID': 1, 'HADM_ID': 2, 'ADMITTIME': 3, 'DISCHTIME': 4, 'DEATHTIME': 5, 'ADMISSION_TYPE': 6, 'ADMISSION_LOCATION': 7, 'DISCHARGE_LOCATION': 8, 'INSURANCE': 9, 'LANGUAGE': 10, 'RELIGION': 11, 'MARITAL_STATUS': 12, 'ETHNICITY': 13, 'EDREGTIME': 14, 'EDOUTTIME': 15, 'DIAGNOSIS': 16, 'HOSPITAL_EXPIRE_FLAG': 17, 'HAS_CHARTEVENTS_DATA': 18})\n",
            "Row((8689, 7124, 109129, datetime.datetime(2188, 7, 11, 0, 58), datetime.datetime(2188, 8, 1, 12, 4), None, 'EMERGENCY', 'EMERGENCY ROOM ADMIT', 'SNF', 'Medicare', None, None, None, 'WHITE', datetime.datetime(2188, 7, 10, 14, 17), datetime.datetime(2188, 7, 11, 1, 52), 'PENILE LACERATION-CELLULITIS', 0, 1), {'ROW_ID': 0, 'SUBJECT_ID': 1, 'HADM_ID': 2, 'ADMITTIME': 3, 'DISCHTIME': 4, 'DEATHTIME': 5, 'ADMISSION_TYPE': 6, 'ADMISSION_LOCATION': 7, 'DISCHARGE_LOCATION': 8, 'INSURANCE': 9, 'LANGUAGE': 10, 'RELIGION': 11, 'MARITAL_STATUS': 12, 'ETHNICITY': 13, 'EDREGTIME': 14, 'EDOUTTIME': 15, 'DIAGNOSIS': 16, 'HOSPITAL_EXPIRE_FLAG': 17, 'HAS_CHARTEVENTS_DATA': 18})\n",
            "Row((12652, 10348, 121510, datetime.datetime(2133, 4, 16, 21, 12), datetime.datetime(2133, 4, 23, 15, 52), None, 'EMERGENCY', 'EMERGENCY ROOM ADMIT', 'SNF', 'Medicare', None, None, None, 'UNKNOWN/NOT SPECIFIED', datetime.datetime(2133, 4, 16, 19, 22), datetime.datetime(2133, 4, 16, 22, 17), 'STATUS EPILEPTICUS', 0, 1), {'ROW_ID': 0, 'SUBJECT_ID': 1, 'HADM_ID': 2, 'ADMITTIME': 3, 'DISCHTIME': 4, 'DEATHTIME': 5, 'ADMISSION_TYPE': 6, 'ADMISSION_LOCATION': 7, 'DISCHARGE_LOCATION': 8, 'INSURANCE': 9, 'LANGUAGE': 10, 'RELIGION': 11, 'MARITAL_STATUS': 12, 'ETHNICITY': 13, 'EDREGTIME': 14, 'EDOUTTIME': 15, 'DIAGNOSIS': 16, 'HOSPITAL_EXPIRE_FLAG': 17, 'HAS_CHARTEVENTS_DATA': 18})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import bigquery\n",
        "\n",
        "# Initialize BigQuery client\n",
        "# client = bigquery.Client()\n",
        "\n",
        "# Define helper function to query datasets\n",
        "def query_datasets():\n",
        "    datasets = client.list_datasets(project='physionet-data')\n",
        "    dataset_names = []\n",
        "\n",
        "    for dataset in datasets:\n",
        "        dataset_names.append(dataset.dataset_id)\n",
        "\n",
        "    return dataset_names\n",
        "\n",
        "# Define helper function to query tables within a dataset\n",
        "def query_tables(dataset_name):\n",
        "    tables = client.list_tables(dataset_name)\n",
        "    table_names = []\n",
        "\n",
        "    for table in tables:\n",
        "        table_names.append(table.table_id)\n",
        "\n",
        "    return table_names\n",
        "\n",
        "# Get the list of dataset names\n",
        "dataset_names = query_datasets()\n",
        "\n",
        "# Print the dataset names\n",
        "print(\"Dataset Names:\")\n",
        "for dataset_name in dataset_names:\n",
        "    print(dataset_name)\n",
        "\n",
        "# Get the list of tables within a dataset\n",
        "#for dataset_name in dataset_names:\n",
        "#    if dataset_name == 'eicu_crd_demo':\n",
        "#        continue  # Skip processing tables for this dataset\n",
        "#    dataset_id = f\"physionet-data.{dataset_name}\"\n",
        "#    table_names = query_tables(dataset_id)\n",
        "#\n",
        "    # Print the table names for each dataset\n",
        "#    print(f\"Tables in dataset {dataset_name}:\")\n",
        "#    for table_name in table_names:\n",
        "#        print(table_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFB__wLtXeVi",
        "outputId": "70f35a5a-2e4e-4964-8d1b-2d8d5aa54ec7"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Names:\n",
            "eicu_crd_demo\n",
            "mimiciii_clinical\n",
            "mimiciii_demo\n",
            "mimiciii_derived\n",
            "mimiciii_notes\n",
            "mimiciv_derived\n",
            "mimiciv_hosp\n",
            "mimiciv_icu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hospital stay demographics\n",
        "Copied from [MIMIC Code Repository](https://github.com/MIT-LCP/mimic-code/blob/main/mimic-iv/notebooks/tableone.ipynb)\n"
      ],
      "metadata": {
        "id": "2Qh7IO47hrC6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy query from code repository\n",
        "hosp_query = \"\"\"\n",
        "SELECT\n",
        "      pat.subject_id\n",
        "    , adm.hadm_id\n",
        "    , DENSE_RANK() OVER hadm_window AS hosp_stay_num\n",
        "    , CASE\n",
        "        WHEN FIRST_VALUE(adm.hadm_id) OVER hadm_window = adm.hadm_id THEN 1\n",
        "        ELSE 0\n",
        "      END AS pat_count\n",
        "    , pat.anchor_age + (EXTRACT(YEAR FROM adm.admittime) - pat.anchor_year) AS age\n",
        "    , pat.gender\n",
        "    , adm.insurance\n",
        "    , DATETIME_DIFF(adm.dischtime, adm.admittime, HOUR) / 24 AS hosp_los\n",
        "    , pat.dod\n",
        "    , DATE_DIFF(pat.dod, CAST(adm.dischtime AS DATE), DAY) AS days_to_death\n",
        "    -- mortality flags\n",
        "    , CASE WHEN DATE_DIFF(pat.dod, CAST(adm.dischtime AS DATE), DAY) = 0 THEN 1 ELSE 0 END AS hospital_mortality\n",
        "FROM `physionet-data.mimiciv_hosp.patients` pat\n",
        "INNER JOIN `physionet-data.mimiciv_hosp.admissions` adm\n",
        "    ON pat.subject_id = adm.subject_id\n",
        "WINDOW hadm_window AS (PARTITION BY pat.subject_id ORDER BY adm.admittime)\n",
        "\"\"\"\n",
        "\n",
        "# Query dataset and store in dataframe\n",
        "hosp = client.query(query).to_dataframe()\n",
        "\n",
        "# add 1 year mortality\n",
        "# hosp['one_year_mortality'] = hosp['days_to_death'].notnull().astype(int) # days_to_death not present. Must be computed\n",
        "\n",
        "# create a dataframe with the days to death for only the last ICU stay\n",
        "# last_dod = hosp.groupby('subject_id')[['hosp_stay_num']].max().reset_index()\n",
        "# last_dod = last_dod.merge(hosp[['subject_id', 'hosp_stay_num', 'days_to_death']], on=['subject_id', 'hosp_stay_num'], how='inner')\n",
        "# last_dod.rename(columns={'days_to_death': 'days_to_death_last_stay_id'}, inplace=True)\n",
        "\n",
        "# hosp = hosp.merge(last_dod, how='left', on=['subject_id', 'hosp_stay_num'])\n",
        "# del last_dod\n",
        "# hosp.sort_values(['subject_id', 'hosp_stay_num'], inplace=True)\n",
        "\n",
        "# fix some data type issues\n",
        "int_cols = hosp.dtypes.values==\"Int64\"\n",
        "hosp.loc[:, int_cols] = hosp.loc[:, int_cols].astype(float)\n",
        "hosp.loc[:, int_cols] = hosp.loc[:, int_cols].astype(int, errors=\"ignore\")\n",
        "\n",
        "print(hosp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xxqj6rkhp7Y",
        "outputId": "93498408-b0de-4656-ff93-57ac28726163"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ROW_ID  SUBJECT_ID  HADM_ID           ADMITTIME           DISCHTIME  \\\n",
            "0    3757        3115   134067 2139-02-13 03:11:00 2139-02-20 07:33:00   \n",
            "1    8689        7124   109129 2188-07-11 00:58:00 2188-08-01 12:04:00   \n",
            "2   12652       10348   121510 2133-04-16 21:12:00 2133-04-23 15:52:00   \n",
            "\n",
            "  DEATHTIME ADMISSION_TYPE    ADMISSION_LOCATION DISCHARGE_LOCATION INSURANCE  \\\n",
            "0       NaT      EMERGENCY  EMERGENCY ROOM ADMIT                SNF  Medicare   \n",
            "1       NaT      EMERGENCY  EMERGENCY ROOM ADMIT                SNF  Medicare   \n",
            "2       NaT      EMERGENCY  EMERGENCY ROOM ADMIT                SNF  Medicare   \n",
            "\n",
            "  LANGUAGE RELIGION MARITAL_STATUS              ETHNICITY           EDREGTIME  \\\n",
            "0     None     None           None                  WHITE 2139-02-13 00:02:00   \n",
            "1     None     None           None                  WHITE 2188-07-10 14:17:00   \n",
            "2     None     None           None  UNKNOWN/NOT SPECIFIED 2133-04-16 19:22:00   \n",
            "\n",
            "            EDOUTTIME                     DIAGNOSIS  HOSPITAL_EXPIRE_FLAG  \\\n",
            "0 2139-02-13 03:22:00                    STAB WOUND                     0   \n",
            "1 2188-07-11 01:52:00  PENILE LACERATION-CELLULITIS                     0   \n",
            "2 2133-04-16 22:17:00            STATUS EPILEPTICUS                     0   \n",
            "\n",
            "   HAS_CHARTEVENTS_DATA  \n",
            "0                     1  \n",
            "1                     1  \n",
            "2                     1  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-42-c46680f1d33c>:42: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
            "  hosp.loc[:, int_cols] = hosp.loc[:, int_cols].astype(float)\n",
            "<ipython-input-42-c46680f1d33c>:42: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
            "  hosp.loc[:, int_cols] = hosp.loc[:, int_cols].astype(float)\n",
            "<ipython-input-42-c46680f1d33c>:42: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
            "  hosp.loc[:, int_cols] = hosp.loc[:, int_cols].astype(float)\n",
            "<ipython-input-42-c46680f1d33c>:42: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
            "  hosp.loc[:, int_cols] = hosp.loc[:, int_cols].astype(float)\n",
            "<ipython-input-42-c46680f1d33c>:42: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
            "  hosp.loc[:, int_cols] = hosp.loc[:, int_cols].astype(float)\n",
            "<ipython-input-42-c46680f1d33c>:43: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
            "  hosp.loc[:, int_cols] = hosp.loc[:, int_cols].astype(int, errors=\"ignore\")\n",
            "<ipython-input-42-c46680f1d33c>:43: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
            "  hosp.loc[:, int_cols] = hosp.loc[:, int_cols].astype(int, errors=\"ignore\")\n",
            "<ipython-input-42-c46680f1d33c>:43: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
            "  hosp.loc[:, int_cols] = hosp.loc[:, int_cols].astype(int, errors=\"ignore\")\n",
            "<ipython-input-42-c46680f1d33c>:43: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
            "  hosp.loc[:, int_cols] = hosp.loc[:, int_cols].astype(int, errors=\"ignore\")\n",
            "<ipython-input-42-c46680f1d33c>:43: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
            "  hosp.loc[:, int_cols] = hosp.loc[:, int_cols].astype(int, errors=\"ignore\")\n"
          ]
        }
      ]
    }
  ]
}